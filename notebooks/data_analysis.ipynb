{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtin modules\n",
    "import re, json, sys\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# external modules\n",
    "import ampal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# load local functions\n",
    "sys.path.append('../src')\n",
    "from data_gen_utils import *\n",
    "\n",
    "\n",
    "# define the path to the colabfold results\n",
    "colabfold_dir = Path('../../data/colabfold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate AF2 scores\n",
    "\n",
    "Combine all a summary of all the AF2 scores into a single file. Takes ~ 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all JSON score files from the colabfold directory\n",
    "score_paths = colabfold_dir.glob('*_scores_rank_*.json')\n",
    "\n",
    "# Initialise an empty list to store score-related data\n",
    "scores_lst = []\n",
    "\n",
    "# Loop through each JSON score file path\n",
    "for p in score_paths:\n",
    "    # Extract the register (b, c, g) and rank number from the filename using regex\n",
    "    reg, rank, seed = re.search('CC-Hex2-AB-3-([a-z]{1})_scores_rank_(\\d{3})_.*_seed_(\\d{3})', p.stem).groups()\n",
    "\n",
    "    # Open and load the JSON file data\n",
    "    with p.open('r') as json_obj:\n",
    "        json_data = json.load(json_obj)\n",
    "    \n",
    "    # Calculate the summary scores for plDDT and pAE values from the loaded JSON data\n",
    "    metric_scores = {}\n",
    "    for metric in ['plddt', 'pae']:\n",
    "        metric_scores[f'min_{metric}'] = np.min(json_data[metric])\n",
    "        metric_scores[f'lq_{metric}'] = np.quantile(json_data[metric], 0.25)\n",
    "        metric_scores[f'med_{metric}'] = np.quantile(json_data[metric], 0.5)\n",
    "        metric_scores[f'mean_{metric}'] = np.mean(json_data[metric])\n",
    "        metric_scores[f'std_{metric}'] = np.std(json_data[metric])\n",
    "        metric_scores[f'uq_{metric}'] = np.quantile(json_data[metric], 0.75)\n",
    "        metric_scores[f'max_{metric}'] = np.max(json_data[metric])\n",
    "\n",
    "    # Extract pTM and ipTM scores from the JSON data\n",
    "    ptm = json_data['ptm']\n",
    "    iptm = json_data['iptm']\n",
    "\n",
    "    # format the PDB path\n",
    "    pdb_path = colabfold_dir / (p.stem.replace('scores', 'unrelaxed') + '.pdb')\n",
    "    \n",
    "    # Append the extracted and calculated values to the list as a dictionary\n",
    "    scores_lst.append({\n",
    "        'register': reg, 'pdb_path': pdb_path, 'score_path': p, 'rank': int(rank), 'seed': seed, \\\n",
    "        'ptm': ptm, 'iptm': iptm, **metric_scores\n",
    "    })\n",
    "\n",
    "# Convert the list of scores into a pandas DataFrame\n",
    "scores_df = pd.DataFrame(scores_lst)\n",
    "\n",
    "# sort the results\n",
    "sorted_df = scores_df.sort_values(by=['register', 'rank'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Z-shfit\n",
    "\n",
    "<img src=\"../assets/delta_z_example.png\" alt=\"Zshift\" width=\"200\"/>\n",
    "\n",
    "The Z-shift is calculated as the distance between the projections of the centroids of each helix (gray spheres) onto the super helical axis (red spheres).  For demonstration an antiparallel di-mer is shown (PDB ID: 7Q1T). Takes ~ 20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise emtpy columns to store the results\n",
    "sorted_df['orientation'] = ''\n",
    "sorted_df['dZ'] = np.nan\n",
    "\n",
    "# Loop through each register ('b', 'c', 'g') and their corresponding structure paths\n",
    "for reg in sorted_df.register.unique():\n",
    "\n",
    "    # Enumerate through the PDB paths for each register\n",
    "    for row_idx, row in sorted_df.query('register == @reg').iterrows():\n",
    "        \n",
    "        # Load the PDB file and select the first model (assuming multi-model PDBs)\n",
    "        ampal_pdb = ampal.load_pdb(row['pdb_path'])[0]\n",
    "\n",
    "        # Calculate the center of mass for the backbone of each chain in the structure\n",
    "        coms = [ampal_pdb[chain.id].backbone.centre_of_mass for chain in ampal_pdb]\n",
    "\n",
    "        # Initialize a list to store the Z-shift values between atoms\n",
    "        dZ = []\n",
    "        \n",
    "        # Loop through pairs of center of mass coordinates to compute the Z-shift\n",
    "        for i, atom1 in enumerate(coms):\n",
    "            for atom2 in coms[i:]:\n",
    "                # Calculate the Z-shift between atoms and append to the list\n",
    "                dZ.append(calculate_z_shift_between_atoms(ampal_pdb, atom1, atom2))\n",
    "                \n",
    "        # Determine if the chains are parallel ('p') or anti-parallel ('ap')\n",
    "        ori = p_or_ap(ampal_pdb)\n",
    "\n",
    "        # Append the results for the current PDB, including region, id, max Z-shift, and orientation\n",
    "        sorted_df.loc[row_idx, 'orientation'] = ori\n",
    "        sorted_df.loc[row_idx, 'dZ'] = max(dZ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange the columns\n",
    "sorted_df = sorted_df[[\n",
    "    'register', 'rank', 'orientation', 'seed', 'dZ',\n",
    "    'min_plddt', 'lq_plddt', 'med_plddt', 'mean_plddt',\n",
    "    'std_plddt','uq_plddt', 'max_plddt', 'min_pae', 'lq_pae',\n",
    "    'med_pae', 'mean_pae','std_pae', 'uq_pae', 'max_pae',\n",
    "    'ptm', 'iptm', 'pdb_path', 'score_path'\n",
    "]]\n",
    "\n",
    "# save the dataframe for future use\n",
    "sorted_df.to_csv(colabfold_dir / 'af_scores_dZ.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMScoring and clustering\n",
    "\n",
    "<img src=\"../assets/tmscoring.png\" alt=\"tmscoring\" width=\"500\"/>\n",
    "\n",
    "In the paper, we cluster the high confidence (pTM > 0.7) AF2 predictions of the CC-Hex2-AB-3-***g*** to show the two structural classes of parallel and antiparallel helix orientations. This code enables the reproduction of our method. Takes ~ 15 minutes on 4 CPU cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the path the US align programme\n",
    "path_to_USalign = '/Users/jc17773/Downloads/USalign-master/USalign'\n",
    "\n",
    "# read the file with scores\n",
    "sorted_df = pd.read_csv(colabfold_dir / 'af_scores_dZ.csv')\n",
    "\n",
    "# select only the confident g-register sequences\n",
    "g_filtered_df = sorted_df.query('register == \"g\" and iptm > 0.7')\n",
    "\n",
    "# get the PDB paths for filtered files\n",
    "g_pdb_paths = g_filtered_df.pdb_path.values\n",
    "\n",
    "# define a path to write results\n",
    "g_tmscores_path = colabfold_dir / 'af_g-reg_TMscores.tsv'\n",
    "\n",
    "# Prepare the output file 'g_alignment.tsv' and write the header for the alignment results\n",
    "g_tmscores_path.write_text('PDBchain1\\tPDBchain2\\tTM1\\tTM2\\tRMSD\\tID1\\tID2\\tIDali\\tL1\\tL2\\tLali\\n')\n",
    "\n",
    "# Append alignment results to the output file, using parallel processing to speed up the task\n",
    "with g_tmscores_path.open('a') as f:\n",
    "    # Create a thread pool to execute multiple tasks concurrently (max 8 threads)\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        # Submit alignment tasks to the thread pool for all pairs \n",
    "        # of structures in 'ranks_to_process'\n",
    "        future_to_pair = {\n",
    "            executor.submit(run_usalign, p1, p2, path_to_USalign): (p1, p2)\n",
    "            for p1 in g_pdb_paths\n",
    "            for p2 in g_pdb_paths\n",
    "        }\n",
    "\n",
    "        # As each task completes, write the result to the output file\n",
    "        for future in as_completed(future_to_pair):\n",
    "            result = future.result()  # Get the result of the alignment\n",
    "            f.write(result + '\\n')    # Append the result to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nr/f_s693214v54fjs9khpwyfnc0000gq/T/ipykernel_34488/2105797111.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  g_filtered_df['cluster'] = cluster_labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>register</th>\n",
       "      <th>rank</th>\n",
       "      <th>orientation</th>\n",
       "      <th>seed</th>\n",
       "      <th>dZ</th>\n",
       "      <th>min_plddt</th>\n",
       "      <th>lq_plddt</th>\n",
       "      <th>med_plddt</th>\n",
       "      <th>mean_plddt</th>\n",
       "      <th>std_plddt</th>\n",
       "      <th>...</th>\n",
       "      <th>med_pae</th>\n",
       "      <th>mean_pae</th>\n",
       "      <th>std_pae</th>\n",
       "      <th>uq_pae</th>\n",
       "      <th>max_pae</th>\n",
       "      <th>ptm</th>\n",
       "      <th>iptm</th>\n",
       "      <th>pdb_path</th>\n",
       "      <th>score_path</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>75</td>\n",
       "      <td>0.082253</td>\n",
       "      <td>84.56</td>\n",
       "      <td>94.015</td>\n",
       "      <td>96.560</td>\n",
       "      <td>95.216087</td>\n",
       "      <td>3.681121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.795073</td>\n",
       "      <td>2.642873</td>\n",
       "      <td>2.70</td>\n",
       "      <td>17.78</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>../../data/colabfold/CCHex2AB-g_unrelaxed_rank...</td>\n",
       "      <td>../../data/colabfold/CCHex2AB-g_scores_rank_00...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>g</td>\n",
       "      <td>3</td>\n",
       "      <td>ap</td>\n",
       "      <td>3</td>\n",
       "      <td>5.557587</td>\n",
       "      <td>78.19</td>\n",
       "      <td>92.910</td>\n",
       "      <td>95.715</td>\n",
       "      <td>94.601667</td>\n",
       "      <td>4.186086</td>\n",
       "      <td>...</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.880784</td>\n",
       "      <td>2.824284</td>\n",
       "      <td>2.76</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>../../data/colabfold/CCHex2AB-g_unrelaxed_rank...</td>\n",
       "      <td>../../data/colabfold/CCHex2AB-g_scores_rank_00...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     register  rank orientation  seed        dZ  min_plddt  lq_plddt  \\\n",
       "3000        g     1           p    75  0.082253      84.56    94.015   \n",
       "3002        g     3          ap     3  5.557587      78.19    92.910   \n",
       "\n",
       "      med_plddt  mean_plddt  std_plddt  ...  med_pae  mean_pae   std_pae  \\\n",
       "3000     96.560   95.216087   3.681121  ...     1.97  2.795073  2.642873   \n",
       "3002     95.715   94.601667   4.186086  ...     2.04  2.880784  2.824284   \n",
       "\n",
       "      uq_pae  max_pae   ptm  iptm  \\\n",
       "3000    2.70    17.78  0.90  0.90   \n",
       "3002    2.76    21.50  0.89  0.88   \n",
       "\n",
       "                                               pdb_path  \\\n",
       "3000  ../../data/colabfold/CCHex2AB-g_unrelaxed_rank...   \n",
       "3002  ../../data/colabfold/CCHex2AB-g_unrelaxed_rank...   \n",
       "\n",
       "                                             score_path  cluster  \n",
       "3000  ../../data/colabfold/CCHex2AB-g_scores_rank_00...        1  \n",
       "3002  ../../data/colabfold/CCHex2AB-g_scores_rank_00...        2  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "2    170\n",
       "1      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the alignment data from a TSV file and sort it by PDBchain1 and PDBchain2 columns\n",
    "alignment_df = pd.read_csv(g_tmscores_path, sep='\\t').sort_values(['PDBchain1', 'PDBchain2'])\n",
    "\n",
    "# Calculate a normalized TM-score by adjusting the TM1 value based on the alignment length (Lali) and sequence length (L1)\n",
    "alignment_df['TMnorm'] = alignment_df['TM1'] * (alignment_df['Lali'] / alignment_df['L1'])\n",
    "\n",
    "# Extract the rank of each PDB chain from the 'PDBchain1' and 'PDBchain2' columns and convert to integer\n",
    "alignment_df['rank1'] = alignment_df['PDBchain1'].str.extract('.*rank_(\\d{3})').astype(int)\n",
    "alignment_df['rank2'] = alignment_df['PDBchain2'].str.extract('.*rank_(\\d{3})').astype(int)\n",
    "\n",
    "# Create a pivot table where 'rank1' is the index, 'rank2' is the column, and the values are the normalized TM-scores (TMnorm)\n",
    "tm_df = pd.pivot_table(data=alignment_df, index='rank1', columns='rank2', values='TMnorm')\n",
    "\n",
    "# Convert the TM-score matrix into a TM distance matrix (TM-score is converted to distance by subtracting from 1)\n",
    "tm_dist_arr = 1 - tm_df.values\n",
    "\n",
    "# Ensure the distance matrix is symmetric by averaging it with its transpose\n",
    "tm_dist_matrix = tm_dist_arr\n",
    "tm_dist_matrix = (tm_dist_matrix + tm_dist_matrix.T) / 2\n",
    "\n",
    "# Convert the symmetric TM distance matrix into a condensed distance matrix (needed for hierarchical clustering)\n",
    "condensed_rmsd = squareform(tm_dist_matrix)\n",
    "\n",
    "# Perform hierarchical clustering using the complete linkage method\n",
    "Z = sch.linkage(condensed_rmsd, method='complete')\n",
    "\n",
    "# Set the distance threshold to define clusters (TMscore is inverted now so distance of 0.05 = 0.95 TMscore)\n",
    "distance_threshold = 0.05\n",
    "\n",
    "# Assign cluster labels to each data point based on the distance threshold\n",
    "cluster_labels = sch.fcluster(Z, distance_threshold, criterion='distance')\n",
    "\n",
    "# Add the cluster labels to the dataframe, clusters are ordered by AF-M rank, as is the dataframe\n",
    "g_filtered_df['cluster'] = cluster_labels\n",
    "\n",
    "# As the dataframe is already sorted by AF-M rank, we can drop cluster duplciates and keep the \n",
    "# first entry to get best model scores for each cluster\n",
    "display(g_filtered_df.drop_duplicates('cluster', keep='first'))\n",
    "\n",
    "# Here we count the number of values in each cluster (1 is parallel, 2 is antiparallel)\n",
    "display(g_filtered_df.value_counts('cluster'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
